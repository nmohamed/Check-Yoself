<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Check Yo-Self by nmohamed</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Check Yo-Self</h1>
      <h2 class="project-tagline">A python program that helps you check your form when weight lifting.</h2>
      <a href="https://github.com/nmohamed/Check_Yo-self" class="btn">View on GitHub</a>
      <a href="https://github.com/nmohamed/Check_Yo-self/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/nmohamed/Check_Yo-self/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="check-yourself" class="anchor" href="#check-yourself" aria-hidden="true"><span class="octicon octicon-link"></span></a>Check Yourself</h1>

<h2>
<a id="helping-you-prevent-yourself-from-injuries" class="anchor" href="#helping-you-prevent-yourself-from-injuries" aria-hidden="true"><span class="octicon octicon-link"></span></a>Helping you prevent yourself from injuries</h2>

<p>By Nora Mohamed (<a href="https://github.com/nmohamed" class="user-mention">@nmohamed</a>), Cindy Sun (<a href="https://github.com/xmsun" class="user-mention">@xmsun</a>), Jason Lan (<a href="https://github.com/Ziyilan" class="user-mention">@Ziyilan</a>), and Zarin Bhuiyan (<a href="https://github.com/zbhuiyan" class="user-mention">@zbhuiyan</a>).</p>

<h3>
<a id="reflection--synthesis-document-for-code-review" class="anchor" href="#reflection--synthesis-document-for-code-review" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reflection &amp; Synthesis Document for Code Review</h3>

<p><strong>Feedback and decisions</strong>
We plan to use the model view controller UML format and look into using LEDs or light as markers so that our program is less dependant on surroundings and possibly using QR codes instead of fiducials. On the code structure side, we decided to incorporate a larger superclass from which we would inherit general functions for specific exercises. This would work by passing angles to the constructor. The general functions we have in mind would include “is straight” or “is 90 degrees” to make our code more concise and efficient.</p>

<p><strong>Review process reflection</strong>
The design review went as we had expected. We got some valuable feedbacks to answer our main questions. The context we provided to the audiences was sufficient enough to let them engage in the discussion while not too much to occupy the majority of the time. One thing we think helpful is that we provided audiences the chance to try our prototype themselves so that they can give us more useful feedbacks.  </p>

<p>We stayed close to our planned agenda and followed it. We planned on demonstrating our program to the audience, and we stuck with the questions we had. Something we could do next time to have an even more effective code review is to give the audience more context to what we’re doing. This applied to the other groups as well, but it was difficult to give advice to the other groups/get advice because our projects aren’t very similar to each other, so we don’t know a lot of things that could be helpful to the other teams/vice versa. We also could’ve had more code to review, because that might mean we have more issues with our code and thus more questions.</p>

<h3>
<a id="preparation--framing-document-for-code-review" class="anchor" href="#preparation--framing-document-for-code-review" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparation &amp; Framing Document for Code Review</h3>

<p><strong>Background and context</strong></p>

<p>We are currently able to detect colored markers and recognize the angle between each marker. However, we have found that the color detection depends heavily on the lighting of the room and the given conditions of the environment. Therefore, we plan to replace these color markers with fiducials in order to increase the accuracy of marker detection and recognition. We have currently had a bit of difficulty with installing ArUco, the library we will use for fiducials, and calibrating the camera. Now that we are able to detect markers and angles, we are also looking to integrate this into the GUI so that the user can view a tutorial video and follow along. After the feedback from the last design review, we are also keeping in mind audio feedback. We have determined that our code architecture will be organized by functions (such as determining a straight line) and implemented for each exercise, rather than organized by exercises.</p>

<p><strong>Key questions</strong></p>

<p>Our main objective for this code review is to get constructive feedback on our current prototype of marker detection, especially on the ease of use. We would also like some feedback on ways to organize our code more efficiently, particularly whether we should group our code by specific functions or exercise classes. Additionally, our questions revolve around allowing the application to adjust to the background automatically, especially when using color markers. Lastly, we are open to any advice regarding fiducials; for example, we are still looking for a more convenient library to use.</p>

<p><strong>Agenda for technical review session</strong></p>

<p>We will first give an overview of our current progress through the presentation and our code, which will be a little less than 10 minutes if we open up the room to questions and feedback. We will also interrupt our presentation at the end to demonstrate to the audience how our application works. The audience will have the opportunity to try out and give verbal feedback for the prototype, which will take around 5 minutes.</p>

<h3>
<a id="reflection-and-synthesis-for-design-review" class="anchor" href="#reflection-and-synthesis-for-design-review" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reflection and Synthesis for Design Review</h3>

<p><strong>Feedback and decisions</strong>:</p>

<p>Our goal for the technical review was to gather feedback on which methods of tracking and posture analysis, as well as some design feedback. For methods of tracking, we initially planned to use the computer’s camera to track and analyze movement using markers but were unsure how to process the frames. However, the audience suggested that we could consider other methods of tracking, such as using a Kinect or integrating with a fitbit/other pieces of hardware. This is less “finnicky” than using markers and a camera, for which we would have to take perspective into consideration.</p>

<p>Originally, we had thought to take a picture or video of the user exercising and compare it with our database of the correct posture for the exercise. However, it was pointed out that people may feel uncomfortable about having their pictures and videos stored, and suggested using a less personal method such as just lines. Additionally, the audience pointed out that we should analyze the entire exercise for posture correction rather than just the separate stages, since movement between each stage could also be incorrect.</p>

<p>Other advice and suggestions we found really helpful was potentially making our program into an application so that it is more portable and open to a wider variety of users. We should also add a disclaimer into our program so that users are aware that we are not professional exercise coaches. </p>

<p>Going forward, we will try using a Kinect, as well as implement the audio feedback and simplifying the images (skeletal rather than videos and pictures). We plan to make the feedback real-time, so the user will get a better sense of what they’re doing. We also decided that we care more about learning instead of useabillity, so we’ll instead focus on making something that satisfies our own goals instead of something that other people can easily use. </p>

<p>Some new questions we generated are: how similar would other fitness tracking apps be to our program? Do you think that we should make the program work for multiple perspectives? What other ways can we make our program more portable?</p>

<p><strong>Review process reflection</strong>:</p>

<p>Most of the part of our design review went well as expected. We got various answers to our main questions and had some valuable discussion with the audiences. From the discussion, we got to look at our project from some aspects we’ve never thought of before, for instance: making some of the design decisions not only from the technical perspective, but from the customer need as well. We provided enough context for the audience to understand what we are doing and how our program would work, since there weren’t many questions on clarifying what we were doing. Our group followed our agenda fairly well and presented as planned, although we didn’t utilize all of our time and had several minutes leftover in our design review. This is mostly because we wanted to keep our presentation short, so we would have more time for questions and feedback. Next time we’ll try to strike a better balance between our presentation time and time sought for feedback.</p>

<h3>
<a id="preparation-and-framing-for-design-review" class="anchor" href="#preparation-and-framing-for-design-review" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparation and Framing for Design Review</h3>

<p><strong>Background and context</strong>
The goal of our project is to create a program that will teach and correct users’ postures when exercising. It utilizes OpenCV to track the movement of the user. Depending on the method of tracking you use and the way to check if you’re maintaining proper posture, this could be difficult (due to lack of accuracy). People have different shapes and sizes, so comparing to a standard body wouldn't be very accurate. There are also some things that are hard to track with a lot of accuracy, like the straightness of a back. Tkinter is the GUI
You’d be prompted to do certain stages of the exercise, following the pictures on the screen. After doing that, you’d be given time to do the exercise (which is recorded). The video of you doing the exercise is compared to pictures of you in certain stages. </p>

<p><strong>Key questions</strong></p>

<ul>
<li>Do you know of any relevant python libraries that aren’t difficult for people to install?</li>
<li>What method of tracking do you think is the most effective and within the scope of this project?</li>
<li>What are some other methods of comparing your posture to correct posture?</li>
</ul>

<p><strong>Agenda for technical review session</strong></p>

<ul>
<li>Powerpoint presentation (visuals)</li>
<li>Technical discussion</li>
<li>Prototype Feedback</li>
</ul>

<h3>
<a id="project-proposal" class="anchor" href="#project-proposal" aria-hidden="true"><span class="octicon octicon-link"></span></a>Project Proposal</h3>

<p><strong>The Big Idea</strong>: The main idea of this project is to create a program that checks your physical form when weight lifting to help you correct it and prevent injury. We will explore the topic of physical fitness and maintaining proper posture to avoid injury. We plan on using OpenCV, a webcam, and information on weight lifting postures. Our MVP is a program that corrects your posture for one type of exercise. A stretch goal is to perfect the accuracy, and also include multiple types of exercises.</p>

<p><strong>Learning Goals</strong>: We all want to get better at Python and learn how to use OpenCV. We want to improve our knowledge of proper form for exercising. We want to get better at designing the framework for programming, and creating/following a viable schedule. We want to also learn how to program in team efficiently and effectively. </p>

<p><strong>Implementation Plan</strong>: We want to use OpenCV and Pygame to draw on top of the image of the user. We can use a GUI for deciding on the type of exercise you’re doing, if we get to the point of doing multiple exercises. How our program should work: you stand in front of your webcam, do your exercise, and the program will mark red the areas where your posture is incorrect.</p>

<p><strong>Project schedule</strong>: You have 6 weeks (roughly) to finish the project.  Sketch out a rough schedule for completing the project.  Depending on your project, you may be able to do this in great specificity or you may only be able to give a broad outline.  Additionally, longer projects come with increased uncertainty, and this schedule will likely need to be refined along the way.</p>

<p>Preliminary schedule (subject to change):</p>

<p>Week 1
Objective: Research OpenCV, methods to track movement, film ourselves doing exercises, create GUI framework
Deliverable: Have a GUI, have videos of the exercises</p>

<p>Week 2
Objective: Video Processing, Tracking Movement (Pushup), Finalize methods of processing video (computer animation v. stock video for tutorial; motion capture v. comparing videos)
Deliverable: Take picture of you in different positions of exercise
Be able to register key parts of your body (back, knee/elbow angles, etc.)</p>

<p>Week 3
Objective: Video Processing, Tracking Movement (Pushup)
Deliverable: Determine which points of the body to analyze
Compare your pushup to correct/proper form</p>

<p>Week 4
Objective: Finalize Pushup, Add two/three new exercises, Update GUI
Deliverable: Figure out for sure how to compare your pushup and provide analysis/feedback</p>

<p>Week 5
Objective: Finalize Pushup, Add two/three new exercises, Update GUI
Deliverable: TBD*</p>

<p>Week 6
Objective: Add exercises, debug/testing, comment and clean up code, push to github
Deliverable: TBD*</p>

<p>Meeting Times: SLAC 8:00-X, Sunday 8:00 PM, and other days for when we separate into subteams</p>

<p>*The deliverables for the last two weeks depends on our progress on pushups at that point. If feasible, we will add additional exercises.</p>

<p><strong>Collaboration plan</strong>: We plan to spend the set meeting times to all work together and make sure everyone’s code works with each other’s. We plan to properly use Github branches as people in the industry use it. We will probably separate into subteams of 2 teams of 2 eventually, where those subteams will decide on when to meet (since it’s easier to coordinate meetings). We want to use pair programming, since we think it is an effective method to programming in pairs.</p>

<p><strong>Risks</strong>: Hurting ourselves when trying to test the program, not getting OpenCV to work the way we will need it to, not knowing how to code what we want to code and general library/python problems. Efficiently sharing our code on GitHub might also be difficult. We will also need to make sure we have a schedule with which we can implement and combine everything with timeliness.</p>

<p><strong>Additional Course Content</strong>: More details on OpenCV (motion tracking, image comparison) would be useful to do in class.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/nmohamed/Check_Yo-self">Check Yo-Self</a> is maintained by <a href="https://github.com/nmohamed">nmohamed</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>

